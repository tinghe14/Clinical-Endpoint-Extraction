# ðŸ§¬ Tumor Measurement Extraction via Instruction-Tuned LLMs
This project implements an end-to-end clinical NLP pipeline to extract tumor size and other measurement-related endpoints from oncology pathology reports. It benchmarks rule-based approaches against instruction-tuned large language models (LLaMA) fine-tuned via QLoRA.

## Project Highlights
1. Pipeline: End-to-end system from raw pathology report â†’ preprocessing â†’ rule-based extraction â†’ LLM extraction â†’ evaluation.
2. Rule-Based Baseline: Designed regex and pattern-matching extractors for tumor size, which exclude  depth of invasion, and metastatic focus size.
3. Instruction-Tuned Model: Used QLoRA and PyTorch to instruction-tune LLaMA on a labeled corpus of clinical measurement examples.

## Tech Stack
- Python, PyTorch, HuggingFace Transformers, QLoRA
- spaCy for preprocessing and NER scaffolding
- Pandas, Scikit-learn for evaluation

## Example Input / Output
- Input (pathology report):
"The tumor measured 3.2 cm in greatest dimension. Depth of invasion: 1.1 cm. Metastatic focus: 0.4 cm."
- Output: 3.2 cm

## Repo Structure

1. Preprocessing:
2. Modeling:
	- Apply rule-based regex system
	- Apply BERT model
	- Apply instruct-tuning LLM models
3. Evaluation

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_reports/
â”‚   â””â”€â”€ annotations/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ llama_finetune/
â”‚   â””â”€â”€ rule_based/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ extract_rule.py
â”‚   â””â”€â”€ finetune_llama.py
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ evaluate_results.py
â”œâ”€â”€ README.md

## How to Run
1. Fine-tune LLaMA using QLoRA
python scripts/finetune_llama.py --train data/train.json --output_dir models/llama_finetune
2. Run extraction using fine-tuned model
python scripts/extract_llama.py --input data/test.json --model_dir models/llama_finetune
3. Evaluate performance
python evaluation/evaluate_results.py --pred results.json --gold data/test_labels.json
